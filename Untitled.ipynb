{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "import jieba.analyse\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\yousheng\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.257 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天 听 啊 去不去 啊 到底\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(jieba.cut('今天听啊去不去啊到底')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今天', '听', '啊', '去不去', '啊', '到底']\n"
     ]
    }
   ],
   "source": [
    "print(list(jieba.cut('今天听啊去不去啊到底')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['小明', '硕士', '毕业', '中国科学院', '计算所', '日本京都大学', '深造']\n"
     ]
    }
   ],
   "source": [
    "text = \"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"\n",
    "data = jieba.cut(text)\n",
    "# data = [word.encode('utf-8') for word in list(data)]\n",
    "with open('stopwords.txt',encoding='utf-8') as f:\n",
    "    stoplist= {}.fromkeys([line.strip() for line in f.readlines()])\n",
    "# stoplist = {}.fromkeys([line.strip() for line in open(\"/Users/yifengjiao/PycharmProjects/dbcomments/stopwords.txt\")])\n",
    "\n",
    "segs = [word for word in list(data) if word not in stoplist]\n",
    "print(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pythonprojects\\lenv\\test\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "f:\\pythonprojects\\lenv\\test\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = word2vec.Word2Vec.load('model/Word60.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('网易', 0.8390017747879028),\n",
       " ('微博', 0.8253723382949829),\n",
       " ('twitter', 0.8215327262878418),\n",
       " ('网络平台', 0.8124679327011108),\n",
       " ('Gmail', 0.8109621405601501),\n",
       " ('新浪', 0.8072453737258911),\n",
       " ('相册', 0.8024308681488037),\n",
       " ('QQ', 0.7987663745880127),\n",
       " ('SNS', 0.7983791828155518),\n",
       " ('搜狐', 0.7966798543930054)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.most_similar(u'微信')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('抗日救国', 0.8040018081665039),\n",
       " ('救国', 0.7974086999893188),\n",
       " ('爱国人士', 0.7945908308029175),\n",
       " ('反共', 0.7885774970054626),\n",
       " ('爱港', 0.7846775650978088),\n",
       " ('反帝', 0.7589733600616455),\n",
       " ('文艺界', 0.7382158041000366),\n",
       " ('爱国运动', 0.7211222648620605),\n",
       " ('同志', 0.7203545570373535),\n",
       " ('反战', 0.7200614809989929)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.most_similar('爱国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod['爱'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3812799"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments/dbcomments_dunkrik.csv',encoding='utf-8') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    rows=[]\n",
    "    for row in f_csv:\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_csv.reader"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['是否看过', '日期', '评星', '赞成数', '评论内容']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0][2] == '力荐'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvalue(text):\n",
    "    if \"很差\" == text:\n",
    "        return 1\n",
    "    elif \"较差\" == text:\n",
    "        return 2\n",
    "    elif \"还行\" == text:\n",
    "        return 3\n",
    "    elif \"推荐\" == text:\n",
    "        return 4\n",
    "    elif \"力荐\" == text:\n",
    "        return 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutwords(text):\n",
    "    data = jieba.cut(text)\n",
    "#     data = [word.encode('utf-8') for word in list(data)]\n",
    "    with open('stopwords.txt',encoding='utf-8') as f:\n",
    "        stoplist= {}.fromkeys([line.strip() for line in f.readlines()])\n",
    "    stoplist[' ']=None\n",
    "    stoplist['\\n']=None\n",
    "    segs = [word for word in list(data) if word not in stoplist]\n",
    "    return segs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'你好' in mod.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros([13322,60,60])\n",
    "Y_train = np.zeros([13322])\n",
    "num = 0\n",
    "for row in rows:\n",
    "    line = cutwords(row[-1])\n",
    "    length = len(line)\n",
    "    if row[2]=='None':\n",
    "        continue\n",
    "#     for i in range(int(length/60)):\n",
    "#         np.append(X_train,np.asarray(line[i*60:i*60+60]))\n",
    "#         np.append(Y_train,getvalue(row[2]))\n",
    "#         k=i\n",
    "    if length>60:\n",
    "        line = line[:60]\n",
    "        length = 60\n",
    "    j=0\n",
    "    for word in line:\n",
    "        if word in mod.vocab:\n",
    "            X_train[num][j] = mod[word]\n",
    "#         else: print(word,'not in the vec vocab')\n",
    "        j +=1\n",
    "#     X_train[num][:length]=line\n",
    "    Y_train[num]=getvalue(row[2])\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 5., 3., 5.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[:num]\n",
    "Y_train = Y_train[:num]\n",
    "Y_train[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6485, 60, 60)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.90649569, -1.77760625, -1.17501688, -1.18881452,  2.27818251,\n",
       "       -1.75391555,  1.00074589,  0.86347914, -1.39148927,  1.86285365,\n",
       "        0.21264696,  0.4180167 ,  1.34068894,  0.78366524,  0.18526274,\n",
       "        0.31186402,  0.57969266, -0.25291717, -0.20382251, -1.40680337,\n",
       "        1.2915417 , -0.1841246 , -0.02821393,  1.0755825 , -1.01581907,\n",
       "        1.47804499, -0.88525373, -0.60766745, -0.53433871, -1.04203403,\n",
       "        1.76465738, -1.34233236, -0.92984986,  0.820876  , -1.83053124,\n",
       "        0.80786598, -0.32051682, -0.69983041, -0.48659572,  0.22244744,\n",
       "       -1.13975441,  1.49108565, -2.65964675,  0.20952563, -0.02098851,\n",
       "        3.30548906, -0.99983764,  1.06478798,  0.31236857,  0.6448282 ,\n",
       "       -0.00660454,  0.99604964,  0.88756949, -2.41082096,  0.74379146,\n",
       "        1.82365406,  2.29820585, -0.50394285,  0.86080128, -1.73272419])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_train,Y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5188, 60, 60)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5188,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1297,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train,num_classes=6)\n",
    "Y_test = to_categorical(Y_test,num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.delete(Y_train,0,axis=1)\n",
    "Y_test = np.delete(Y_test,0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5188, 5)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pythonprojects\\lenv\\test\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  import sys\n",
      "f:\\pythonprojects\\lenv\\test\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(60, 60), units=128)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "input_length=60\n",
    "input_dim=60\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(output_dim=128,\n",
    "               input_dim=input_dim,\n",
    "               input_length=input_length,\n",
    "               \n",
    "                   ))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5188 samples, validate on 1297 samples\n",
      "Epoch 1/200\n",
      "5188/5188 [==============================] - 16s 3ms/step - loss: 1.2777 - acc: 0.3805 - val_loss: 1.2231 - val_acc: 0.4086\n",
      "Epoch 2/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2614 - acc: 0.3897 - val_loss: 1.2563 - val_acc: 0.3670\n",
      "Epoch 3/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2439 - acc: 0.3851 - val_loss: 1.2368 - val_acc: 0.3678\n",
      "Epoch 4/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2394 - acc: 0.3842 - val_loss: 1.2200 - val_acc: 0.3678\n",
      "Epoch 5/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2358 - acc: 0.3921 - val_loss: 1.2152 - val_acc: 0.4086\n",
      "Epoch 6/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2351 - acc: 0.3830 - val_loss: 1.2126 - val_acc: 0.4117\n",
      "Epoch 7/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2357 - acc: 0.3842 - val_loss: 1.2119 - val_acc: 0.4102\n",
      "Epoch 8/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2357 - acc: 0.3892 - val_loss: 1.2128 - val_acc: 0.4109\n",
      "Epoch 9/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2303 - acc: 0.3899 - val_loss: 1.2098 - val_acc: 0.3955\n",
      "Epoch 10/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2189 - acc: 0.3955 - val_loss: 1.2038 - val_acc: 0.4079\n",
      "Epoch 11/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2165 - acc: 0.3951 - val_loss: 1.2171 - val_acc: 0.4086\n",
      "Epoch 12/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 1.2120 - acc: 0.3776 - val_loss: 1.2060 - val_acc: 0.4086\n",
      "Epoch 13/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.2026 - acc: 0.3953 - val_loss: 1.2021 - val_acc: 0.4086\n",
      "Epoch 14/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1921 - acc: 0.3957 - val_loss: 1.2067 - val_acc: 0.3670\n",
      "Epoch 15/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1812 - acc: 0.4015 - val_loss: 1.2039 - val_acc: 0.4194\n",
      "Epoch 16/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1766 - acc: 0.4048 - val_loss: 1.2089 - val_acc: 0.4133\n",
      "Epoch 17/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1522 - acc: 0.4185 - val_loss: 1.2079 - val_acc: 0.4187\n",
      "Epoch 18/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1874 - acc: 0.4152 - val_loss: 1.2064 - val_acc: 0.4002\n",
      "Epoch 19/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1530 - acc: 0.4331 - val_loss: 1.2136 - val_acc: 0.4194\n",
      "Epoch 20/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1209 - acc: 0.4468 - val_loss: 1.2284 - val_acc: 0.4179\n",
      "Epoch 21/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.1037 - acc: 0.4684 - val_loss: 1.1959 - val_acc: 0.4387 1.10\n",
      "Epoch 22/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.0713 - acc: 0.4992 - val_loss: 1.2417 - val_acc: 0.4194\n",
      "Epoch 23/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.0476 - acc: 0.5197 - val_loss: 1.2639 - val_acc: 0.4418\n",
      "Epoch 24/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 1.0233 - acc: 0.5438 - val_loss: 1.2525 - val_acc: 0.4310\n",
      "Epoch 25/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.9852 - acc: 0.5617 - val_loss: 1.2661 - val_acc: 0.4379\n",
      "Epoch 26/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.9850 - acc: 0.5758 - val_loss: 1.3321 - val_acc: 0.4256\n",
      "Epoch 27/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.9253 - acc: 0.6157 - val_loss: 1.3470 - val_acc: 0.4256\n",
      "Epoch 28/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.8750 - acc: 0.6455 - val_loss: 1.3587 - val_acc: 0.4179\n",
      "Epoch 29/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.8299 - acc: 0.6615 - val_loss: 1.4304 - val_acc: 0.4094\n",
      "Epoch 30/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.8140 - acc: 0.6771 - val_loss: 1.5669 - val_acc: 0.4040\n",
      "Epoch 31/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.7371 - acc: 0.7082 - val_loss: 1.6434 - val_acc: 0.4163\n",
      "Epoch 32/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 0.6838 - acc: 0.7338 - val_loss: 1.8133 - val_acc: 0.4187\n",
      "Epoch 33/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 0.7032 - acc: 0.7253 - val_loss: 1.5544 - val_acc: 0.4418\n",
      "Epoch 34/200\n",
      "5188/5188 [==============================] - 14s 3ms/step - loss: 0.9321 - acc: 0.6268 - val_loss: 1.4791 - val_acc: 0.4179\n",
      "Epoch 35/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.7285 - acc: 0.7274 - val_loss: 1.8092 - val_acc: 0.4148\n",
      "Epoch 36/200\n",
      "5188/5188 [==============================] - 15s 3ms/step - loss: 0.6532 - acc: 0.7556 - val_loss: 1.7553 - val_acc: 0.4148\n",
      "Epoch 37/200\n",
      "3424/5188 [==================>...........] - ETA: 4s - loss: 0.6058 - acc: 0.7789"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-c36cf18fc1ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                   metrics=['accuracy'])\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=200,batch_size=32,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "ids = np.load('model/idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9870, 60)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([574287,  52307,    890,  19937,   5621,  30343,  24576,    401,\n",
       "       574287, 574287, 574287, 574287, 574287, 574287, 574287, 574287,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
