{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cutwords(text):\n",
    "    data = jieba.cut(text)\n",
    "#     data = [word.encode('utf-8') for word in list(data)]\n",
    "    with open('stopwords2.txt',encoding='utf-8') as f:\n",
    "        stoplist= {}.fromkeys([line.strip() for line in f.readlines()])\n",
    "    stoplist[' ']=None\n",
    "    stoplist['\\n']=None\n",
    "    segs = [word for word in list(data) if word not in stoplist]\n",
    "    return segs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvalue(text):\n",
    "    if \"很差\" == text:\n",
    "        return 1\n",
    "    elif \"较差\" == text:\n",
    "        return 2\n",
    "    elif \"还行\" == text:\n",
    "        return 3\n",
    "    elif \"推荐\" == text:\n",
    "        return 4\n",
    "    elif \"力荐\" == text:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(file):\n",
    "    # 语料文本内容\n",
    "    rows = []\n",
    "    labels = []\n",
    "    with open(file, 'r',encoding='UTF-8') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        headers = next(f_csv)\n",
    "        for line in f_csv:\n",
    "            if line[2] == 'None' or line[2] == '评分':\n",
    "                continue\n",
    "            rows.append(cutwords(line[-1]))\n",
    "            labels.append(getvalue(line[2]))\n",
    "    return rows,labels\n",
    "\n",
    "#     words = sorted(list(files_content))\n",
    "#     counted_words = {}\n",
    "#     for word in words:\n",
    "#         if word in counted_words:\n",
    "#             counted_words[word] += 1\n",
    "#         else:\n",
    "#             counted_words[word] = 1\n",
    "\n",
    "#     # 去掉低频的字\n",
    "#     erase = []\n",
    "#     for key in counted_words:\n",
    "#         if counted_words[key] <= 2:\n",
    "#             erase.append(key)\n",
    "#     for key in erase:\n",
    "#         del counted_words[key]\n",
    "#     wordPairs = sorted(counted_words.items(), key=lambda x: -x[1])\n",
    "\n",
    "#     words, _ = zip(*wordPairs)\n",
    "#     words += (\" \",)\n",
    "#     # word到id的映射\n",
    "#     word2num = dict((c, i) for i, c in enumerate(words))\n",
    "#     num2word = dict((i, c) for i, c in enumerate(words))\n",
    "#     word2numF = lambda x: word2num.get(x, len(words) - 1)\n",
    "#     return word2numF, num2word, words, files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\yousheng\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 4.481 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "rows,labels = preprocess_file('comments/dbcomments_dunkrik.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['用', '最贵', '的', '演员', '露', '最少', '的', '脸', '诺兰', '哈迪', '传']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_words = {}\n",
    "for row in rows:\n",
    "    for word in row:\n",
    "        if word in counted_words:\n",
    "            counted_words[word] += 1\n",
    "        else:\n",
    "            counted_words[word] = 1\n",
    "\n",
    "wordPairs = sorted(counted_words.items(), key=lambda x: -x[1])\n",
    "words, _ = zip(*wordPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15715"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words += (\" \",)\n",
    "    # word到id的映射\n",
    "word2num = dict((c, i) for i, c in enumerate(words))\n",
    "num2word = dict((i, c) for i, c in enumerate(words))\n",
    "word2numF = lambda x: word2num.get(x, len(words) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2num['好']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15716"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len = len(words)\n",
    "word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2numF('情节')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(rows),60))\n",
    "i=0\n",
    "for row in rows:\n",
    "    if len(row)>60:\n",
    "        row = row[:60]\n",
    "    \n",
    "    j=0\n",
    "    for word in row:\n",
    "        X_train[i,j] = word2numF(word)\n",
    "        j+=1\n",
    "    i+=1\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6485, 60)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, ..., 5, 3, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.asarray(labels)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pythonprojects\\lenv\\test\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_train,Y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5836, 60)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pythonprojects\\lenv\\test\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "mod = word2vec.Word2Vec.load('model/Word60.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "的\n",
      "[-3.11456    -1.1026787   1.3855833  -2.522232   -1.3366619   1.5432111\n",
      " -0.32103094  1.5085886  -5.679984    3.006396    1.6489267   1.2228204\n",
      " -1.340919   -0.26727533 -3.219774   -0.43049592  2.657892    3.8075688\n",
      " -2.0659244   3.2285674   0.7037918  -0.13837029 -0.12925437 -1.963114\n",
      " -0.86781347  0.6664328   2.1167452   2.7126713  -0.8416103   1.5536782\n",
      "  0.9186014  -1.6948516  -0.16411854  0.49102455 -3.1869683   2.07418\n",
      "  0.04535485 -0.7557681   0.46670228  2.4284227   2.061927    0.08018775\n",
      " -3.2604396  -3.2888284  -1.0456715   0.05253574  1.6431937   0.50921893\n",
      "  1.880831    0.15248111  0.9621658   3.196472   -0.00575073 -2.1094005\n",
      " -0.3552529   1.5514581   2.174728    1.8197117   0.21262446 -3.8029437 ]\n"
     ]
    }
   ],
   "source": [
    "print(num2word[0])\n",
    "print(mod[num2word[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=27, max_features=56, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=6,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=40, min_samples_split=6, max_depth=27, max_features=56, oob_score=True)\n",
    "rf1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7974640164496231"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pythonprojects\\lenv\\test\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(recurrent_activation=\"hard_sigmoid\", units=50, activation=\"sigmoid\")`\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = np.zeros((word_len, 60))\n",
    "for i in range(word_len):\n",
    "    if num2word[i] not in mod.vocab:\n",
    "        continue\n",
    "    embedding_weights[i] = mod[num2word[i]]\n",
    "input_length=60\n",
    "input_dim=word_len\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=60,\n",
    "                        input_dim=input_dim,\n",
    "                        mask_zero=True,\n",
    "                        weights=[embedding_weights],\n",
    "                        input_length=input_length))\n",
    "\n",
    "model.add(LSTM(output_dim=50,\n",
    "                   activation='sigmoid',\n",
    "                   inner_activation='hard_sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5836 samples, validate on 649 samples\n",
      "Epoch 1/200\n",
      "5836/5836 [==============================] - 52s 9ms/step - loss: 1.3013 - acc: 0.3850 - val_loss: 1.2314 - val_acc: 0.4314\n",
      "Epoch 2/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 1.2406 - acc: 0.4121 - val_loss: 1.2225 - val_acc: 0.4083\n",
      "Epoch 3/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 1.2218 - acc: 0.4261 - val_loss: 1.2160 - val_acc: 0.4468\n",
      "Epoch 4/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 1.1928 - acc: 0.4558 - val_loss: 1.2068 - val_acc: 0.4515\n",
      "Epoch 5/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 1.1706 - acc: 0.4690 - val_loss: 1.1953 - val_acc: 0.4453\n",
      "Epoch 6/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 1.1351 - acc: 0.5038 - val_loss: 1.1838 - val_acc: 0.4684\n",
      "Epoch 7/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 1.0817 - acc: 0.5327 - val_loss: 1.1769 - val_acc: 0.4607\n",
      "Epoch 8/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 1.0044 - acc: 0.5824 - val_loss: 1.1812 - val_acc: 0.4669\n",
      "Epoch 9/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 0.9241 - acc: 0.6285 - val_loss: 1.2119 - val_acc: 0.4653\n",
      "Epoch 10/200\n",
      "5836/5836 [==============================] - 51s 9ms/step - loss: 0.8306 - acc: 0.6712 - val_loss: 1.2576 - val_acc: 0.4561\n",
      "Epoch 11/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 0.7557 - acc: 0.7068 - val_loss: 1.3353 - val_acc: 0.4807\n",
      "Epoch 12/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 0.6716 - acc: 0.7411 - val_loss: 1.4169 - val_acc: 0.4653\n",
      "Epoch 13/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.6173 - acc: 0.7647 - val_loss: 1.5052 - val_acc: 0.4792\n",
      "Epoch 14/200\n",
      "5836/5836 [==============================] - 50s 8ms/step - loss: 0.5531 - acc: 0.7915 - val_loss: 1.5925 - val_acc: 0.4638\n",
      "Epoch 15/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.4981 - acc: 0.8148 - val_loss: 1.6777 - val_acc: 0.4761\n",
      "Epoch 16/200\n",
      "5836/5836 [==============================] - 50s 9ms/step - loss: 0.4542 - acc: 0.8317 - val_loss: 1.8199 - val_acc: 0.4468\n",
      "Epoch 17/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 0.4286 - acc: 0.8413 - val_loss: 1.9644 - val_acc: 0.4391\n",
      "Epoch 18/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 0.3995 - acc: 0.8494 - val_loss: 1.9721 - val_acc: 0.4792\n",
      "Epoch 19/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 0.3761 - acc: 0.8568 - val_loss: 2.0811 - val_acc: 0.4684\n",
      "Epoch 20/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 0.3516 - acc: 0.8732 - val_loss: 2.1598 - val_acc: 0.4622\n",
      "Epoch 21/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 0.3307 - acc: 0.8727 - val_loss: 2.2560 - val_acc: 0.4545\n",
      "Epoch 22/200\n",
      "5836/5836 [==============================] - 45s 8ms/step - loss: 0.3077 - acc: 0.8821 - val_loss: 2.3400 - val_acc: 0.4576\n",
      "Epoch 23/200\n",
      "5836/5836 [==============================] - 46s 8ms/step - loss: 0.2991 - acc: 0.8891 - val_loss: 2.3307 - val_acc: 0.4638\n",
      "Epoch 24/200\n",
      "5836/5836 [==============================] - 45s 8ms/step - loss: 0.2811 - acc: 0.8919 - val_loss: 2.5027 - val_acc: 0.4653\n",
      "Epoch 25/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 0.2730 - acc: 0.8968 - val_loss: 2.5383 - val_acc: 0.4669\n",
      "Epoch 26/200\n",
      "5836/5836 [==============================] - 47s 8ms/step - loss: 0.2598 - acc: 0.8999 - val_loss: 2.6118 - val_acc: 0.4638\n",
      "Epoch 27/200\n",
      "5836/5836 [==============================] - 50s 9ms/step - loss: 0.2716 - acc: 0.8965 - val_loss: 2.6323 - val_acc: 0.4592\n",
      "Epoch 28/200\n",
      "5836/5836 [==============================] - 50s 9ms/step - loss: 0.2531 - acc: 0.9028 - val_loss: 2.6133 - val_acc: 0.4561\n",
      "Epoch 29/200\n",
      "5836/5836 [==============================] - 52s 9ms/step - loss: 0.2385 - acc: 0.9076 - val_loss: 2.7159 - val_acc: 0.4545\n",
      "Epoch 30/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.2314 - acc: 0.9104 - val_loss: 2.8209 - val_acc: 0.4391\n",
      "Epoch 31/200\n",
      "5836/5836 [==============================] - 52s 9ms/step - loss: 0.2266 - acc: 0.9130 - val_loss: 2.8172 - val_acc: 0.4715\n",
      "Epoch 32/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.2186 - acc: 0.9148 - val_loss: 2.9089 - val_acc: 0.4576\n",
      "Epoch 33/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.2181 - acc: 0.9145 - val_loss: 2.9507 - val_acc: 0.4576\n",
      "Epoch 34/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.2150 - acc: 0.9147 - val_loss: 2.9972 - val_acc: 0.4530\n",
      "Epoch 35/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.2057 - acc: 0.9183 - val_loss: 3.0855 - val_acc: 0.4622\n",
      "Epoch 36/200\n",
      "5836/5836 [==============================] - 50s 9ms/step - loss: 0.2094 - acc: 0.9195 - val_loss: 3.0756 - val_acc: 0.4607\n",
      "Epoch 37/200\n",
      "5836/5836 [==============================] - 50s 9ms/step - loss: 0.2015 - acc: 0.9210 - val_loss: 3.1720 - val_acc: 0.4545\n",
      "Epoch 38/200\n",
      "5836/5836 [==============================] - 51s 9ms/step - loss: 0.1972 - acc: 0.9200 - val_loss: 3.2000 - val_acc: 0.4592\n",
      "Epoch 39/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.1951 - acc: 0.9243 - val_loss: 3.1137 - val_acc: 0.4730\n",
      "Epoch 40/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.2000 - acc: 0.9202 - val_loss: 3.1719 - val_acc: 0.4792\n",
      "Epoch 41/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.1893 - acc: 0.9231 - val_loss: 3.2511 - val_acc: 0.4576\n",
      "Epoch 42/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1889 - acc: 0.9234 - val_loss: 3.1688 - val_acc: 0.4622\n",
      "Epoch 43/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1887 - acc: 0.9246 - val_loss: 3.2388 - val_acc: 0.4622\n",
      "Epoch 44/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1797 - acc: 0.9280 - val_loss: 3.3440 - val_acc: 0.4684\n",
      "Epoch 45/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1785 - acc: 0.9294 - val_loss: 3.4595 - val_acc: 0.4438\n",
      "Epoch 46/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1762 - acc: 0.9285 - val_loss: 3.3274 - val_acc: 0.4730\n",
      "Epoch 47/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1714 - acc: 0.9311 - val_loss: 3.4360 - val_acc: 0.4515\n",
      "Epoch 48/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1732 - acc: 0.9261 - val_loss: 3.4229 - val_acc: 0.4715\n",
      "Epoch 49/200\n",
      "5836/5836 [==============================] - 48s 8ms/step - loss: 0.1709 - acc: 0.9294 - val_loss: 3.5047 - val_acc: 0.4715\n",
      "Epoch 50/200\n",
      "5836/5836 [==============================] - 49s 8ms/step - loss: 0.1648 - acc: 0.9325 - val_loss: 3.5021 - val_acc: 0.4638\n",
      "Epoch 51/200\n",
      "5836/5836 [==============================] - 50s 9ms/step - loss: 0.1683 - acc: 0.9308 - val_loss: 3.4929 - val_acc: 0.4561\n",
      "Epoch 52/200\n",
      "2752/5836 [=============>................] - ETA: 26s - loss: 0.1591 - acc: 0.9346"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c36cf18fc1ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                   metrics=['accuracy'])\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pythonprojects\\lenv\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=200,batch_size=32,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
